# Framework de Testes Backend - Dumont Cloud

Este documento descreve o framework de testes backend criado para o sistema Dumont Cloud, com organizaÃ§Ã£o por mÃ³dulos, cache inteligente e estrutura reutilizÃ¡vel.

## ğŸ—ï¸ Estrutura de DiretÃ³rios

```
tests/backend/
â”œâ”€â”€ conftest.py                    # Framework base e configuraÃ§Ãµes
â”œâ”€â”€ auth/
â”‚   â””â”€â”€ test_login.py            # Testes de autenticaÃ§Ã£o
â”œâ”€â”€ instances/
â”‚   â””â”€â”€ test_gpu_instances.py     # Testes de instÃ¢ncias GPU
â”œâ”€â”€ hibernation/
â”‚   â””â”€â”€ test_auto_hibernation.py # Testes de auto-hibernaÃ§Ã£o
â”œâ”€â”€ snapshots/
â”‚   â””â”€â”€ test_snapshots.py        # Testes de snapshots
â”œâ”€â”€ migration/
â”‚   â””â”€â”€ test_migration.py        # Testes de migraÃ§Ã£o
â”œâ”€â”€ ai_wizard/
â”‚   â””â”€â”€ test_ai_wizard.py       # Testes de AI Wizard
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ test_metrics.py          # Testes de mÃ©tricas
â”œâ”€â”€ sync/
â”‚   â””â”€â”€ test_sync.py             # Testes de sincronizaÃ§Ã£o
â”œâ”€â”€ standby/
â”‚   â””â”€â”€ test_standby.py         # Testes de CPU Standby
â”œâ”€â”€ regions/
â”‚   â””â”€â”€ test_regions.py          # Testes de mapeamento
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ test_dashboard.py       # Testes de dashboard
â”œâ”€â”€ telemetry/
â”‚   â””â”€â”€ test_telemetry.py        # Testes de telemetria
â”œâ”€â”€ alerts/
â”‚   â””â”€â”€ test_alerts.py          # Testes de alertas
â””â”€â”€ e2e/
    â””â”€â”€ test_e2e_complete.py    # Testes end-to-end
```

## ğŸ”§ Framework Base (conftest.py)

### CaracterÃ­sticas Principais

1. **Cache Inteligente**
   - Baseado em hash SHA256 do arquivo de teste
   - Evita re-execuÃ§Ã£o se o arquivo nÃ£o mudou
   - Cache expira em 24 horas
   - ConfigurÃ¡vel via variÃ¡vel de ambiente `TEST_CACHE`

2. **APIClient ReutilizÃ¡vel**
   - AutenticaÃ§Ã£o automÃ¡tica JWT
   - Retry com exponential backoff
   - Timeout configurÃ¡vel
   - Headers padrÃ£o

3. **BaseTestCase**
   - Classe base com mÃ©todos utilitÃ¡rios
   - Logging estruturado com cores
   - Assertions personalizadas
   - Setup/teardown automÃ¡tico

4. **Fixtures Globais**
   - `api_client`: Client autenticado
   - `unauth_client`: Client sem autenticaÃ§Ã£o
   - `sample_instance_data`: Dados de teste para instÃ¢ncias
   - `sample_snapshot_data`: Dados de teste para snapshots

### ConfiguraÃ§Ãµes

```bash
# VariÃ¡veis de ambiente
export TEST_BASE_URL="http://localhost:8766"
export TEST_USER="test@example.com"
export TEST_PASS="test123"
export TEST_TIMEOUT="30"
export TEST_RETRY="3"
export TEST_CACHE="true"  # Habilita cache inteligente
```

## ğŸš€ Como Usar

### Executar Todos os Testes
```bash
# Com cache habilitado (padrÃ£o)
pytest tests/backend/ -v

# Sem cache (sempre executa)
TEST_CACHE=false pytest tests/backend/ -v

# Apenas testes de um mÃ³dulo
pytest tests/backend/auth/ -v

# Apenas testes especÃ­ficos
pytest tests/backend/auth/test_login.py -v -k "test_login"
```

### Executar com Filtros
```bash
# Apenas testes de autenticaÃ§Ã£o
pytest tests/backend/ -v -k "auth"

# Apenas testes de performance
pytest tests/backend/ -v -k "performance"

# Pular testes lentos
pytest tests/backend/ -v -k "not slow"
```

### ParallelizaÃ§Ã£o
```bash
# Executar em paralelo (4 processos)
pytest tests/backend/ -v -n 4

# Distribuir por diretÃ³rio
pytest tests/backend/ -v --dist=loadscope
```

## ğŸ“Š Cache Inteligente

### Como Funciona

1. **Hash do Arquivo**: Calcula SHA256 do arquivo de teste
2. **Chave de Cache**: Combina hash do arquivo + parÃ¢metros
3. **VerificaÃ§Ã£o**: Verifica se resultado existe em cache
4. **Pulamento**: Se cache existe, pula o teste
5. **Armazenamento**: Salva resultado apÃ³s execuÃ§Ã£o

### Estrutura do Cache
```
tests/backend/.test_cache/
â”œâ”€â”€ test_login_hash1_params1.json
â”œâ”€â”€ test_instances_hash2_params2.json
â””â”€â”€ ...
```

### BenefÃ­cios

- **Velocidade**: Testes nÃ£o mudados pulam execuÃ§Ã£o
- **ConsistÃªncia**: Resultados reproducÃ­veis
- **Economia**: Menos carga nos sistemas externos
- **Desenvolvimento**: Feedback mais rÃ¡pido

## ğŸ¯ PadrÃµes de Teste

### Estrutura de uma Classe de Teste
```python
class TestModuleName(BaseTestCase):
    """DescriÃ§Ã£o dos testes deste mÃ³dulo"""
    
    def test_functionality_positive(self, api_client):
        """Teste positivo da funcionalidade"""
        # Preparar dados
        test_data = {...}
        
        # Executar request
        resp = api_client.post("/api/v1/endpoint", json=test_data)
        
        # Validar resposta
        self.assert_success_response(resp, "DescriÃ§Ã£o do sucesso")
        data = resp.json()
        
        # Validar estrutura
        required_keys = ["key1", "key2"]
        self.assert_json_keys(data, required_keys)
        
        # Validar valores
        assert data["key1"] == expected_value
        
        self.log_success("Mensagem de sucesso especÃ­fica")
    
    def test_functionality_negative(self, api_client):
        """Teste negativo da funcionalidade"""
        # Preparar dados invÃ¡lidos
        invalid_data = {...}
        
        # Executar request
        resp = api_client.post("/api/v1/endpoint", json=invalid_data)
        
        # Validar erro
        assert resp.status_code in [400, 422]
        
        self.log_success("ValidaÃ§Ã£o funcionou")
```

### PadrÃµes de Assert

```python
# Sucesso genÃ©rico
self.assert_success_response(resp, "DescriÃ§Ã£o")

# ValidaÃ§Ã£o de JSON
self.assert_json_keys(data, ["required", "keys"])

# Logs especÃ­ficos
self.log_success("Mensagem de sucesso")
self.log_warning("Mensagem de aviso")
self.log_fail("Mensagem de falha")
self.log_info("Mensagem informativa")
```

## ğŸ” Tipos de Teste Implementados

### 1. Testes Funcionais
- ValidaÃ§Ã£o de endpoints
- Fluxos completos de negÃ³cio
- Comportamento esperado

### 2. Testes de ValidaÃ§Ã£o
- Campos obrigatÃ³rios
- Tipos de dados invÃ¡lidos
- Valores fora de range

### 3. Testes de SeguranÃ§a
- Input malicioso
- SQL Injection
- XSS
- Rate limiting

### 4. Testes de Performance
- Tempo de resposta
- RequisiÃ§Ãµes concorrentes
- Load testing bÃ¡sico

### 5. Testes de IntegraÃ§Ã£o
- MÃºltiplos endpoints juntos
- Fluxos complexos
- Dependencies entre sistemas

## ğŸ“ˆ RelatÃ³rios e Resultados

### SaÃ­da PadrÃ£o
```
âœ“ Login OK: token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...
âœ“ Token vÃ¡lido: user=test@example.com
âœ“ Token refresh: novo token gerado e vÃ¡lido
âš  InstÃ¢ncia nÃ£o encontrada para pausa
âœ“ Multi-status: 0/3 encontradas
```

### Cache Status
```
Dumont Cloud Backend Tests
Cache: ENABLED
Base URL: http://localhost:8766
============================================================

âœ“ Login OK: token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...
âœ“ Teste em cache: test_login_success (pulado)
âœ“ Token vÃ¡lido: user=test@example.com
```

### Resultados Finais
```
============================================================
Testes Finalizados
Exit status: 0
============================================================
```

## ğŸ› ï¸ ExtensÃ£o do Framework

### Adicionar Novo MÃ³dulo

1. Criar diretÃ³rio: `tests/backend/novo_modulo/`
2. Criar arquivo: `tests/backend/novo_modulo/test_novo.py`
3. Herdar de `BaseTestCase`
4. Seguir padrÃµes estabelecidos

### Adicionar Novo Fixture
```python
@pytest.fixture(scope="function")
def novo_dado_teste():
    """DescriÃ§Ã£o do fixture"""
    return {
        "campo1": "valor1",
        "campo2": "valor2"
    }
```

### Adicionar Novo Teste de Performance
```python
def test_performance_endpoint(self, api_client):
    """Testa performance do endpoint"""
    start_time = time.time()
    resp = api_client.get("/api/v1/endpoint")
    request_time = time.time() - start_time
    
    self.assert_success_response(resp, "Performance test")
    assert request_time < 2.0, f"Request muito lento: {request_time:.2f}s"
    
    self.log_success(f"Performance: {request_time:.2f}s")
```

## ğŸš¨ Boas PrÃ¡ticas

### 1. Nomenclatura
- Classes: `TestModuleName`
- MÃ©todos: `test_functionality_scenario`
- DescriÃ§Ãµes claras e especÃ­ficas

### 2. Estrutura
- Setup/teardown automÃ¡ticos
- Dados de teste em fixtures
- ValidaÃ§Ãµes explÃ­citas

### 3. Mensagens
- Sempre em portuguÃªs
- Descritivas e claras
- Incluir contexto quando relevante

### 4. Cache
- Testes idempotentes devem usar cache
- Testes com side effects devem desabilitar cache
- Documentar comportamento esperado

### 5. Performance
- Testes rÃ¡pidos priorizados
- Testes lentos marcados com `@pytest.mark.slow`
- Timeout apropriado para cada tipo de teste

## ğŸ”® PrÃ³ximos Passos

1. **Completar mÃ³dulos restantes**: snapshots, migration, ai_wizard, etc.
2. **IntegraÃ§Ã£o CI/CD**: GitHub Actions com cache
3. **Coverage**: RelatÃ³rio de cobertura de cÃ³digo
4. **Performance**: Benchmarking automatizado
5. **Mocking**: Isolar dependÃªncias externas

Este framework fornece uma base sÃ³lida para testes backend do Dumont Cloud, com foco em produtividade, confiabilidade e mantenabilidade.

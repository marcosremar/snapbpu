[pytest]
# Dumont Cloud - Pytest Configuration

# Markers para organizar testes
markers =
    smoke: Smoke tests - devem sempre passar (<10s)
    critical: Fluxos críticos do negócio
    slow: Testes lentos (>5s)
    e2e: Testes end-to-end completos
    visual: Testes visuais com IA
    demo: Testes específicos do modo demo
    frontend: Testes que requerem frontend rodando
    api: Testes de API backend
    order: Ordem de execução dos testes
    contract: API contract validation with Pydantic
    browser_use: Browser-Use AI automation tests
    vibe: Vibe tests - UX & visual validation (10% pyramid)
    gpu: GPU provisioning tests (may cost $$$)
    parallel: Tests designed for parallel execution
    serverless: Serverless (pause/resume) tests
    failover: Failover system tests
    real: Tests that use real credits ($$$)
    model_deploy: Model deployment tests (LLM, Whisper, Diffusers)
    finetune: Fine-tuning tests
    jobs: GPU job execution tests
    agent: Agent heartbeat and metrics tests
    warmpool: Warm pool failover tests
    spot: Spot instance tests
    metrics: Market metrics and analytics tests
    machine_history: Machine reliability and blacklist tests
    snapshots: Snapshot create/restore tests
    settings: Settings and configuration tests
    savings: Savings calculation tests
    creates_machine: Tests that create their own machine (expensive)
    uses_shared_machine: Tests that use shared session machine (cheap)

# Diretórios de teste
testpaths = tests

# Padrões de arquivos de teste
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Output e execução paralela automática
addopts =
    -v
    --tb=short
    --strict-markers
    -n 10

# Timeout padrão (pode ser overridden por teste)
timeout = 30

# Ignore warnings específicos
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)s] %(message)s
log_cli_date_format = %H:%M:%S

# =============================================================================
# PYTEST-TESTMON - Incremental Testing
# =============================================================================
# Só re-executa testes afetados por mudanças no código.
#
# USO:
#   pytest --testmon          # Roda apenas testes afetados por mudanças
#   pytest --testmon-nocollect # Coleta sem rodar (útil após mudanças estruturais)
#   pytest --testmon-forceselect # Força seleção mesmo se nada mudou
#   pytest                    # Roda todos os testes (modo normal)
#
# O testmon cria um arquivo .testmondata que guarda o mapeamento
# código -> testes. Adicione ao .gitignore se não quiser compartilhar.
#
# Para limpar cache: rm .testmondata

# Configuração do cache do pytest (built-in)
cache_dir = .pytest_cache

# =============================================================================
# PYTEST-XDIST - Parallel Testing (10 workers default)
# =============================================================================
# Run tests in parallel using multiple workers.
#
# COMANDOS:
#   pytest tests/backend/api -n 10 -v         # All API tests, 10 parallel
#   pytest tests/backend/api -n 10 -m api     # Only @pytest.mark.api
#   pytest tests/backend/api -n 10 -m "not real"  # Skip real credit tests
#   pytest tests/backend/gpu -n 5 -v          # GPU tests, 5 parallel
#
# MARKERS:
#   @pytest.mark.api        # API endpoint tests
#   @pytest.mark.serverless # Serverless tests
#   @pytest.mark.failover   # Failover tests
#   @pytest.mark.gpu        # GPU provisioning tests
#   @pytest.mark.real       # Uses real credits ($$$)
#   @pytest.mark.slow       # Slow tests (>30s)
#
# EXAMPLES:
#   pytest tests/backend/api/test_all_endpoints.py -n 10 -v
#   pytest tests/backend/api/test_serverless.py -n 10 -v -m "not real"
#   pytest tests/backend/api/test_failover.py -n 10 -v -m "failover and not slow"
#
# Para instalar: pip install pytest-xdist
#
# =============================================================================
# GPU TESTS - REAL CREDITS ENABLED
# =============================================================================
# GPU tests use REAL VAST.ai credits. This is ACCEPTED and EXPECTED.
#
# MARKERS:
#   @pytest.mark.creates_machine   - Tests that CREATE their own machine (expensive)
#   @pytest.mark.uses_shared_machine - Tests that SHARE a single machine (cheap)
#
# COST-OPTIMIZED RUNNING:
#
#   # CHEAPEST: Run shared machine tests (9 tests share 1 GPU = ~$0.02)
#   pytest tests/backend/api/test_gpu_real.py -v -m "uses_shared_machine" -n 1 --timeout=600
#
#   # LIFECYCLE tests (each creates own GPU = ~$0.10-0.15)
#   pytest tests/backend/api/test_gpu_real.py -v -m "creates_machine" -n 4 --timeout=600
#
#   # ALL TESTS (full cost = ~$0.15-0.25)
#   pytest tests/backend/api/test_gpu_real.py -v --timeout=600
#
# IMPORTANT:
#   - Use -n 1 for shared machine tests (otherwise each worker creates its own GPU!)
#   - Lifecycle tests CAN use -n 4 since each creates its own GPU anyway
#   - Default strategy is now "single" instead of "race" to save costs

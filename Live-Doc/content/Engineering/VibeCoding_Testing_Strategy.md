# ğŸš€ VibeCoding Testing Strategy - Dumont Cloud

## Filosofia: MÃ¡ximo Impacto, MÃ­nimo Tempo

Em VibeCoding, o objetivo Ã© **validar rapidamente** que o sistema funciona para o usuÃ¡rio final.
NÃ£o precisamos de 100% de cobertura - precisamos de **100% de confianÃ§a nos fluxos crÃ­ticos**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIRÃ‚MIDE VIBECODING                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                    ğŸ¤– AI Visual Tests                           â”‚
â”‚                   (UI-TARS + Browser-Use)                       â”‚
â”‚                      "EstÃ¡ bonito?"                             â”‚
â”‚                         10%                                     â”‚
â”‚                                                                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚    ğŸ”„ E2E User Journeys     â”‚                    â”‚
â”‚              â”‚  (Playwright + API Mocks)   â”‚                    â”‚
â”‚              â”‚   "Fluxo completo funciona?"â”‚                    â”‚
â”‚              â”‚           20%               â”‚                    â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚         â”‚      ğŸ¯ Critical Path API Tests       â”‚               â”‚
â”‚         â”‚        (Pytest + Demo Provider)       â”‚               â”‚
â”‚         â”‚      "Endpoints crÃ­ticos OK?"         â”‚               â”‚
â”‚         â”‚               30%                     â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚           âš¡ Smoke Tests (Always Run)           â”‚          â”‚
â”‚    â”‚         Health + Auth + Demo Mode               â”‚          â”‚
â”‚    â”‚              "Sistema vivo?"                    â”‚          â”‚
â”‚    â”‚                   40%                           â”‚          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Estado Atual vs Proposto

| Aspecto | Atual | Proposto | BenefÃ­cio |
|---------|-------|----------|-----------|
| **Smoke Tests** | 0 | 10 testes | ValidaÃ§Ã£o em <10s |
| **E2E UIâ†”API** | 0 | 5 jornadas | ConfianÃ§a total |
| **Demo Provider** | 40% | 100% | Demo funcional |
| **Browser-Use** | 0 | 3 cenÃ¡rios | IA testa como humano |
| **UI-TARS** | 88 | 88 (mantÃ©m) | JÃ¡ excelente |
| **Backend API** | 218 | 218 (mantÃ©m) | JÃ¡ completo |

---

## ğŸ¯ EstratÃ©gia em 4 Camadas

### Camada 1: Smoke Tests (Sempre Rodam - 10s)

```bash
# Roda antes de QUALQUER commit
pytest tests/smoke/ -v --timeout=10
```

**Testes Essenciais:**
1. âœ… Backend estÃ¡ vivo (`/health`)
2. âœ… Login funciona (demo user)
3. âœ… Demo mode ativo
4. âœ… Frontend carrega (200 OK)
5. âœ… API retorna ofertas

### Camada 2: Critical Path (PrÃ©-Deploy - 2min)

```bash
# Roda antes de deploy
pytest tests/backend/ -v -m critical --timeout=120
```

**Fluxos CrÃ­ticos:**
1. ğŸ” Auth completo (login â†’ token â†’ refresh â†’ logout)
2. ğŸ–¥ï¸ Busca GPU â†’ Filtros â†’ Resultados
3. ğŸ’° Dashboard â†’ Savings â†’ MÃ©tricas
4. ğŸ”„ Standby â†’ Configure â†’ Status
5. ğŸ“¸ Snapshots â†’ List (erro tratado se nÃ£o configurado)

### Camada 3: E2E com Playwright Agents (Nightly - 10min)

```bash
# Inicializar Playwright Agents
npx playwright init-agents --loop=claude

# Roda toda noite ou antes de release
npx playwright test tests/e2e-journeys/ --workers=1
```

**ğŸ­ Playwright Test Agents (RECOMENDADO):**

| Agente | FunÃ§Ã£o | BenefÃ­cio |
|--------|--------|-----------|
| ğŸ­ **Planner** | Explora app e cria test plan em Markdown | GeraÃ§Ã£o automÃ¡tica |
| ğŸ­ **Generator** | Converte plan em cÃ³digo Playwright | Zero esforÃ§o manual |
| ğŸ­ **Healer** | Auto-corrige testes que falharam | Self-healing nativo |

**Por que Playwright Agents > Midscene.js:**
- âš¡ **Velocidade**: CÃ³digo nativo (~2s) vs API calls (~45s/teste)
- ğŸ”§ **Self-Healing**: Healer Agent corrige locators automaticamente
- ğŸ“ **GeraÃ§Ã£o**: Planner + Generator criam testes a partir de exploraÃ§Ã£o
- ğŸ¢ **Oficial Microsoft**: Suporte garantido

**Jornadas Completas:**
1. **Novo UsuÃ¡rio**: Landing â†’ Demo â†’ Dashboard â†’ Explorar
2. **ML Researcher**: Login â†’ Buscar GPU â†’ Ver PreÃ§os â†’ Deploy
3. **Operador**: Login â†’ MÃ¡quinas â†’ Pausar â†’ Resumir â†’ Migrar
4. **Admin**: Login â†’ Settings â†’ Configurar Standby â†’ Verificar

### Camada 4: AI Visual (Weekly - 5min)

```bash
# Roda semanalmente ou apÃ³s mudanÃ§as de UI
python tests/ui-tars-test/ui_tars_comprehensive_test.py
python tests/browser-use/visual_regression.py
```

**ValidaÃ§Ãµes Visuais:**
1. ğŸ¨ Layout nÃ£o quebrou
2. ğŸ“± Mobile responsivo
3. â™¿ Acessibilidade bÃ¡sica
4. âš¡ Performance aceitÃ¡vel

---

## ğŸ”§ ImplementaÃ§Ãµes NecessÃ¡rias

### 1. Completar Demo Provider (CRÃTICO)

```python
# src/infrastructure/providers/demo_provider.py
# Adicionar mÃ©todos faltantes para demo funcionar 100%

class DemoProvider(IGpuProvider):
    # âœ… JÃ¡ implementado
    def search_offers(...) -> List[GpuOffer]
    def list_instances() -> List[Instance]
    def get_balance() -> Dict

    # âŒ FALTA IMPLEMENTAR
    def create_instance(self, offer_id: int, **kwargs) -> Instance:
        """Simula criaÃ§Ã£o - retorna instÃ¢ncia fake"""
        return Instance(
            id=f"demo-{random.randint(1000,9999)}",
            status="running",
            gpu_name=self._get_offer_gpu(offer_id),
            created_at=datetime.now(),
            # ... outros campos
        )

    def destroy_instance(self, instance_id: str) -> bool:
        """Simula destroy - sempre sucesso"""
        return True

    def pause_instance(self, instance_id: str) -> bool:
        """Simula pause - sempre sucesso"""
        return True

    def resume_instance(self, instance_id: str) -> bool:
        """Simula resume - sempre sucesso"""
        return True
```

### 2. Criar Smoke Tests

```python
# tests/smoke/test_smoke.py
"""
Smoke Tests - ValidaÃ§Ã£o rÃ¡pida do sistema
Tempo mÃ¡ximo: 10 segundos
"""
import pytest
import requests

BASE_URL = "http://localhost:8766"

class TestSmoke:
    """Testes que SEMPRE devem passar"""

    @pytest.mark.smoke
    def test_backend_alive(self):
        """Backend responde"""
        resp = requests.get(f"{BASE_URL}/health", timeout=5)
        assert resp.status_code == 200

    @pytest.mark.smoke
    def test_demo_login(self):
        """Login demo funciona"""
        resp = requests.post(
            f"{BASE_URL}/api/v1/auth/login",
            json={"username": "test@test.com", "password": "test123"},
            timeout=5
        )
        assert resp.status_code == 200
        assert "token" in resp.json()

    @pytest.mark.smoke
    def test_demo_mode_active(self):
        """Demo mode retorna ofertas"""
        resp = requests.get(
            f"{BASE_URL}/api/v1/instances/offers?demo=true",
            timeout=5
        )
        # 200 = ofertas, 500/503 = API externa (OK em demo)
        assert resp.status_code in [200, 500, 503]

    @pytest.mark.smoke
    def test_frontend_loads(self):
        """Frontend carrega"""
        resp = requests.get("http://localhost:5173", timeout=5)
        assert resp.status_code == 200
```

### 3. Criar E2E User Journeys

```javascript
// tests/e2e-journeys/new-user-journey.spec.js
const { test, expect } = require('@playwright/test');

test.describe('Jornada: Novo UsuÃ¡rio', () => {

  test('Landing â†’ Demo â†’ Dashboard â†’ Explorar', async ({ page }) => {
    // 1. Chega na landing
    await page.goto('/');
    await expect(page.locator('text=Dumont Cloud')).toBeVisible();

    // 2. Clica em "Try Demo"
    await page.click('button:has-text("Demo")');

    // 3. Verifica redirecionamento para dashboard
    await expect(page).toHaveURL(/.*dashboard/);

    // 4. VÃª cards de economia
    await expect(page.locator('[data-testid="savings-card"]')).toBeVisible();

    // 5. Navega para Machines
    await page.click('text=Machines');
    await expect(page).toHaveURL(/.*machines/);

    // 6. VÃª lista de GPUs
    await expect(page.locator('[data-testid="gpu-list"]')).toBeVisible();

    // 7. Usa filtro
    await page.fill('[data-testid="gpu-search"]', 'RTX 4090');
    await page.waitForTimeout(500); // Debounce

    // 8. Verifica resultados filtrados
    const gpuCards = page.locator('[data-testid="gpu-card"]');
    await expect(gpuCards.first()).toContainText('4090');
  });

});
```

### 4. Integrar Browser-Use

```python
# tests/browser-use/user_simulation.py
"""
Browser-Use: IA simula usuÃ¡rio real
"""
from browser_use import Agent, Browser

async def test_deploy_wizard_flow():
    """IA navega pelo Deploy Wizard como usuÃ¡rio"""

    browser = Browser()
    agent = Agent(
        task="""
        1. VÃ¡ para http://localhost:5173
        2. Clique no botÃ£o de Demo
        3. No Dashboard, encontre o Deploy Wizard
        4. Selecione o tier "RÃ¡pido"
        5. Escolha regiÃ£o "US East"
        6. Clique em "Ver Ofertas"
        7. Verifique se apareceram GPUs disponÃ­veis
        8. Tire screenshot do resultado
        """,
        llm=your_llm,  # Claude, GPT-4, etc
        browser=browser
    )

    result = await agent.run()

    # ValidaÃ§Ãµes
    assert "GPUs disponÃ­veis" in result.final_state
    assert result.screenshots[-1].contains("ofertas")
```

---

## ğŸ“ Estrutura Proposta

```
tests/
â”œâ”€â”€ smoke/                          # âš¡ Smoke tests (10s)
â”‚   â”œâ”€â”€ conftest.py
â”‚   â””â”€â”€ test_smoke.py              # 5 testes essenciais
â”‚
â”œâ”€â”€ backend/                        # ğŸ¯ API tests (existente)
â”‚   â”œâ”€â”€ conftest.py                # Framework base
â”‚   â”œâ”€â”€ auth/                      # 16 testes
â”‚   â”œâ”€â”€ instances/                 # 22 testes
â”‚   â”œâ”€â”€ standby/                   # 27 testes
â”‚   â””â”€â”€ ...                        # Total: 218 testes
â”‚
â”œâ”€â”€ e2e-journeys/                   # ğŸ”„ User journeys (NOVO)
â”‚   â”œâ”€â”€ new-user-journey.spec.js
â”‚   â”œâ”€â”€ ml-researcher-journey.spec.js
â”‚   â”œâ”€â”€ operator-journey.spec.js
â”‚   â””â”€â”€ admin-journey.spec.js
â”‚
â”œâ”€â”€ browser-use/                    # ğŸ¤– AI automation (NOVO)
â”‚   â”œâ”€â”€ user_simulation.py
â”‚   â”œâ”€â”€ visual_regression.py
â”‚   â””â”€â”€ accessibility_check.py
â”‚
â”œâ”€â”€ ui-tars-test/                   # ğŸ‘ï¸ Visual AI (existente)
â”‚   â”œâ”€â”€ ui_tars_comprehensive_test.py
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ playwright/                     # ğŸ­ UI tests (existente)
    â”œâ”€â”€ dashboard.spec.js
    â”œâ”€â”€ machines.spec.js
    â””â”€â”€ ...                        # 50 specs
```

---

## â±ï¸ Pipeline de ExecuÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     QUANDO RODAR O QUÃŠ                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“ A cada SAVE (hot reload):                                   â”‚
â”‚     â””â”€â”€ Nada (deixa o dev em paz)                               â”‚
â”‚                                                                 â”‚
â”‚  ğŸ’¾ A cada COMMIT:                                              â”‚
â”‚     â””â”€â”€ Smoke Tests (10s)                                       â”‚
â”‚         pytest tests/smoke/ -v --timeout=10                     â”‚
â”‚                                                                 â”‚
â”‚  ğŸš€ A cada PUSH/PR:                                             â”‚
â”‚     â””â”€â”€ Smoke + Critical Path (2min)                            â”‚
â”‚         pytest tests/smoke/ tests/backend/ -v -m "smoke or critical" â”‚
â”‚                                                                 â”‚
â”‚  ğŸŒ™ NIGHTLY (3am):                                              â”‚
â”‚     â””â”€â”€ Tudo (15min)                                            â”‚
â”‚         pytest tests/ -v                                        â”‚
â”‚         npx playwright test                                     â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“¦ Antes de RELEASE:                                           â”‚
â”‚     â””â”€â”€ Tudo + AI Visual (20min)                                â”‚
â”‚         pytest tests/ -v                                        â”‚
â”‚         npx playwright test                                     â”‚
â”‚         python tests/ui-tars-test/ui_tars_comprehensive_test.py â”‚
â”‚         python tests/browser-use/visual_regression.py           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Markers para Pytest

```python
# pytest.ini ou pyproject.toml
[tool.pytest.ini_options]
markers = [
    "smoke: Testes rÃ¡pidos que sempre devem passar",
    "critical: Fluxos crÃ­ticos do negÃ³cio",
    "slow: Testes lentos (>5s)",
    "e2e: Testes end-to-end",
    "visual: Testes visuais com IA",
    "demo: Testes especÃ­ficos do modo demo",
]
```

**Uso:**
```bash
# SÃ³ smoke
pytest -m smoke

# Smoke + Critical
pytest -m "smoke or critical"

# Tudo menos slow
pytest -m "not slow"

# SÃ³ E2E
pytest -m e2e
```

---

## ğŸ¤– LLMs Recomendados para Playwright Agents

### Via OpenRouter (Recomendado)

Pesquisa de mercado 2025 identificou os melhores modelos:

| Modelo | Performance | Custo | RecomendaÃ§Ã£o |
|--------|-------------|-------|--------------|
| **Claude Sonnet 4** | â­â­â­â­â­ (77.2% SWE-bench) | $3/$15 per 1M tokens | ğŸ† **MELHOR para Agentic Coding** |
| **Claude Sonnet 4.5** | â­â­â­â­â­ | $3/$15 per 1M tokens | ğŸ¥‡ Mais recente, melhor reasoning |
| **Qwen 2.5 VL 72B** | â­â­â­â­ | ~$0.20/$0.20 per 1M tokens | ğŸ’° **MELHOR CUSTO-BENEFÃCIO** |
| **GPT-4o** | â­â­â­â­ | $5/$15 per 1M tokens | âœ… EstÃ¡vel e confiÃ¡vel |
| **DeepSeek V3** | â­â­â­â­ | ~$0.14/$0.28 per 1M tokens | ğŸ’¸ Mais barato, bom para volume |

### ConfiguraÃ§Ã£o com OpenRouter

```bash
# .env
OPENROUTER_API_KEY=sk-or-v1-xxxxx
OPENROUTER_MODEL=anthropic/claude-sonnet-4

# Ou para economia:
# OPENROUTER_MODEL=qwen/qwen-2.5-vl-72b-instruct
```

### Inicializar Playwright Agents

```bash
# Com Claude (recomendado)
npx playwright init-agents --loop=claude

# Com VS Code + Copilot
npx playwright init-agents --loop=vscode

# Com OpenCode (OpenRouter)
npx playwright init-agents --loop=opencode
```

### Por que Claude Sonnet 4?

> "Sonnet 4 is considered the best model in agentic coding. Note that it doesn't mean it is the greatest at generating code, it also excels at choosing the right tools for the task."
> â€” Awesome Testing, 2025

**Vantagens:**
1. **Visually grounded** - Entende UI screenshots
2. **Instruction following** - Segue specs precisamente
3. **Planning** - Excelente em criar test plans
4. **Tool use** - Sabe quando usar cada ferramenta

### Alternativa EconÃ´mica: Qwen 2.5 VL 72B

Para projetos com orÃ§amento limitado:
- **15x mais barato** que Claude
- **Performance comparÃ¡vel** para tarefas simples
- **Self-hostable** para privacidade
- **Visually grounded** (entende screenshots)

```bash
# Via OpenRouter
OPENROUTER_MODEL=qwen/qwen-2.5-vl-72b-instruct
```

---

## ğŸ”® Coisas "MÃ¡gicas" para Adicionar

### 1. Auto-Healing Tests
```python
# Se um seletor quebrar, IA encontra o novo
@auto_heal
def test_click_deploy_button(page):
    page.click('[data-testid="deploy-btn"]')  # Se falhar, IA busca alternativa
```

### 2. Screenshot Diff AutomÃ¡tico
```python
# Compara screenshots e alerta se mudou muito
@visual_regression(threshold=0.05)  # 5% de diferenÃ§a tolerada
def test_dashboard_visual(page):
    page.goto('/dashboard')
    page.screenshot(path='dashboard.png')
```

### 3. Performance Budget
```python
# Falha se performance degradar
@performance_budget(
    first_contentful_paint=1500,  # ms
    largest_contentful_paint=2500,
    time_to_interactive=3000
)
def test_dashboard_performance(page):
    page.goto('/dashboard')
```

### 4. Chaos Testing (Opcional)
```python
# Simula falhas para testar resiliÃªncia
@chaos_test(
    kill_backend_probability=0.1,
    slow_network_probability=0.2
)
def test_system_resilience(page):
    # Sistema deve se recuperar graciosamente
    pass
```

---

## ğŸ“ˆ MÃ©tricas de Sucesso

| MÃ©trica | Meta | Como Medir |
|---------|------|------------|
| **Smoke Pass Rate** | 100% | CI/CD |
| **Critical Path Pass Rate** | >98% | CI/CD |
| **E2E Journey Pass Rate** | >95% | Nightly |
| **Tempo de Smoke** | <10s | CI/CD |
| **Tempo Total de Testes** | <15min | Nightly |
| **Cobertura Fluxos CrÃ­ticos** | 100% | Manual review |

---

## ğŸš€ ImplementaÃ§Ã£o RÃ¡pida (VibeCoding Style)

### Fase 1: Hoje (2h)
1. âœ… Criar `tests/smoke/test_smoke.py` com 5 testes
2. âœ… Adicionar markers no `pytest.ini`
3. âœ… Testar: `pytest -m smoke`

### Fase 2: Esta Semana (4h)
1. ğŸ”„ Completar Demo Provider (mÃ©todos faltantes)
2. ğŸ”„ Criar 2 E2E journeys em Playwright
3. ğŸ”„ Configurar CI para rodar smoke em PRs

### Fase 3: PrÃ³xima Semana (4h)
1. ğŸ“‹ Adicionar Browser-Use para 1 cenÃ¡rio
2. ğŸ“‹ Configurar nightly run completo
3. ğŸ“‹ Dashboard de mÃ©tricas de testes

---

## ğŸ’¡ Dicas VibeCoding para Testes

1. **NÃ£o teste tudo** - Teste o que quebra o usuÃ¡rio
2. **Smoke primeiro** - Se smoke falha, nada mais importa
3. **Demo Ã© rei** - Se demo nÃ£o funciona, cliente nÃ£o compra
4. **IA para visual** - Humano nÃ£o deveria verificar pixels
5. **Falhe rÃ¡pido** - Timeout agressivo nos testes
6. **Paralelize** - Testes devem ser independentes
7. **Mock externo** - NÃ£o dependa de Vast.ai/GCP nos testes

---

**Ãšltima atualizaÃ§Ã£o**: 2025-12-19
**Autor**: Engineering Team
**Filosofia**: "Se o usuÃ¡rio consegue fazer, o teste consegue verificar"
